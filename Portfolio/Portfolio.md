<h1>Persoonlijke Portfolio</h1>

Het persoonlijke portfolio voor de minor Data Science aan de Haagse Hogeschool

* <b>Naam</b>: Askin Sarikaya
* <b>Studentnummer</b>: 14121409
* <b>E-mail</b>: 14121409@student.hhs.nl


# Table of contents
1. [Introductie](#Introductie)
2. [Domain Knowledge](#Domein)
    1. [Jargon](#Jargon)
    2. [Literatuur](#Jargon)    
3. [Courses](#Courses)
   1. [Datacamp Courses](#Datacamp)
   2. [Coursera](#Coursera)
   4

## This is the introduction <a name="introduction"></a>
Some introduction text, formatted in heading 2 style

## Some paragraph <a name="paragraph1"></a>
The first paragraph text

### Sub paragraph <a name="subparagraph1"></a>
This is a sub paragraph, formatted in heading 3 style

## Another paragraph <a name="paragraph2"></a>
The second paragraph text



<h2>Introductie</h2>

Voor onze minor Data Science aan de Haagse Hogeschool hebben wij in een groep van 4 mensen een opdracht uitgevoerd namens het CBS.
Daarbij werd er getracht de top 10 categorieen, van gegeven data van het CBS, eruit te filteren.
Data die door het CBS beschikbaar is gesteld en tevens gebruikt is voor deze opdracht zijn de gestelde vragen per e-mail aan het CBS.
Omdat dit zodanig groot bleek te zijn, door het aantal categorieen waarin vragen kunnen worden gesteld meer dan 180 bleek, hebben wij ons als groep beperkt tot 2 datasets:

* Inkomen
* Bevolkingsgroep

Deze datasets hebben wij handmatig gelabeld en vervolgens geprobeerd om ons algoritme op los te laten. Daarbij hebben wij voornamelijk volgende modellen gebruikt:

* Multionomial Naive Bayes
* Complement Naive Bayes
* Logistic Regression

Dit waren ook tevens de modellen met het beste resultaat op onze skewed dataset. 

<h1>Domein</h1>

<h2>Jargon</h2>

* Naive Bayes =
* Skewed Dataset =
* Logistic Regression =
* Data Cleaning =
* Programmeren = 
* Machine Learning =
* Data Visualisatie =
* Data Manipuleren = 
* Data Importeren =
* Pentesting = 


<h2>Literatuur</h2>
<h1>Courses</h1>
In dit hoofdstuk worden de benodigde en extra opdrachten die gemaakt zijn toegelicht.

<h2>Datacamp</h2>


![Afgeronde Courses](/Portfolio/Courses/Alle%20assignments%20+.png)
![Afgeronde Hele Courses](/Portfolio/Courses/Voltooide%20Courses.png)

Alle benodigde opdrachten beschreven in de wekelijkse agenda voor datacamp zijn voltooid. 
Hieronder wordt per course een korte stuk beschreven over de toegevoegde waarde van de course ten behoeve van mijn ontwikkeling.


* <b> Programmeren </b> (19100 XP)
1. (Course) [Introduction to Python](https://www.datacamp.com/courses/intro-to-python-for-data-science)
2. (Course) [Intermediate Python for Data Science](https://www.datacamp.com/courses/intro-to-python-for-data-science)
3. (Chapter) [Writing your own functions](https://www.datacamp.com/courses/python-data-science-toolbox-part-1)
4. (Chapter) [Default arguments, variable-length arguments and scope](https://www.datacamp.com/courses/python-data-science-toolbox-part-1)
5. (Course) [Python Data Science Toolbox (Part 2)](https://www.datacamp.com/courses/python-data-science-toolbox-part-2)

Het leren van het programmeren van Python heeft er tot bijgedragen dat ik op een basis-gevorderd niveau Python code kan begrijpen. 
Dit zorgde direct ervoor dat bij het lezen van de code gemaakt (vooral tutorials gevolgd op internet) door de programmeurs van de groep, de code niet vreemd overkwam bij mij op persoon.
Dit zorgde er tevens voor dat ik gericht ideeen/feedback kon geven passend op de haalbaarheid van de opdracht zonder dat dit buiten proporties kwam te liggen.

Boven alles heeft dit ervoor gezorgd dat ik kundiger met Linux en tegelijk met Python ben geworden. Dit heeft ervoor gezorgd dat ik in mijn eigen vakgebied (IT - Security) scripts kan begrijpen & schrijven als ik bijvoorbeeld iets aan het pentesten ben.
Deze relatie had ik voorheen niet kunnen leggen en dit is zodoende ook een grote positieve bijdrage in mijn carriere.


* <b> Importeren en Cleanen van Data </b> (8020 XP)
1. (Chapter) [Importing Data in Python (Part 1)](https://www.datacamp.com/courses/importing-data-in-python-part-1) & Mandatory
2. (Course) [Introduction and flat files](https://www.datacamp.com/courses/importing-data-in-python-part-1)
3. (Course) [Cleaning data in Python](https://www.datacamp.com/courses/cleaning-data-in-python)

* <b> Data Manipulatie </b> (2080 XP)
1. (Chapter) [Data ingestion & inspection](https://www.datacamp.com/courses/pandas-foundations)
2. (Chapter) [Exploratory Data Analysis](https://www.datacamp.com/courses/pandas-foundations)

* <b> Data Visualisatie </b> (3520 XP)
1. (Chapter) [Plotting 2D Arrays](https://www.datacamp.com/courses/introduction-to-data-visualization-with-python)
2. (Chapter) [Statistical plots with Seaborn](https://www.datacamp.com/courses/introduction-to-data-visualization-with-python)
3. (Chapter) [Customizing Plots](https://www.datacamp.com/courses/introduction-to-data-visualization-with-python)

* <b> Waarschijnlijkheid & Statistiek </b> (4350 XP)
1. (Course) [Statistical Thinking in Python (Part 1)](https://www.datacamp.com/courses/statistical-thinking-in-python-part-1)

* <b> Machine Learning </b> (4300 XP)
1. (Course) [Supervised Learning with scikit-learn](https://www.datacamp.com/courses/supervised-learning-with-scikit-learn)


<h2>Coursera</h2>


Voor Coursera zijn de weken 1,2,3 en 6 afgerond. De bijbehorende opdrachten zijn daarbij niet gemaakt. 
Alle quiz onderdelen zijn met een voldoende afgerond.

![Coursera](/Portfolio/Courses/Timeline%20Coursera.png)


De video's van Coursera en de bijbehorende quiz hebben bijgedragen tot een betere kennis op het gebied van machine learning. 
Bij Datacamp lag de focus meer op het toepassen en programmeren. Bij Coursera werd de achterliggende gedachte, formules etc. het gehele concept uitgelegd over machine learning dus ook toepassen.
Dat ik de stof begreep getuigd ook van mijn voldoende op de toets. Tevens zorgde het bestuderen van Coursera ervoor dat ik nieuwe ideeen opdeed en dit zorgde er direct voor dat bepaalde handelingen veel makkelijker konden uitgevoerd. Immers, wij begrepen het concept van machine learning veel beter nu.


<h2>Python Notebooks

<h1>Data & Modellen</h1>
<h2>Predictive Models</h2>


Hier stuk over supervised learning, classification of regression. Python bestand multiclass classification
<h2>Data preparation</h2>
Stuk over labelen, check bestand python labelen, in bestanden bijvoorbeeld de lege plekken een 0 geven.
<h2>Data Visualization</h2>
Stuk over confusion matrix, in code en gebruik plaatjes van de 2 error analyse


<h2>Data collection</h3>
Stuk over labelen
<h2>Evaluation</h3>
Zelf iets maken 
Underfit, Overfit, Bias

<h2>Diagnostics of the learning process</h2>

<h1>Communicatie</h1>
<h2>Presentaties</h2>

Presentaties zijn altijd gezamenlijk gemaakt met de inbreng van de groep. Omdat ik, zoals aangegeven, meer in de kant van het onderzoeken was, presenteerde ik ook veel meer. 
In totaal heb ik 10 keer gepresenteerd waarvan 2 keer alleen. 

Presentaties per week:

* [Week 1](/Presentaties/2018.08.31-intro.pptx)
* [Week 2](/Presentaties/2018.09.07%20Presentatie.pptx) 
* [Week 3](/Presentaties/2018.09.10%20CBS%20Presentatie.pptx)
* [Week 4](/Presentaties/2018.09.14%20Presentatie.pptx)
* [Week 5](/Presentaties/2018.09.21%20CBS%20Presentatie.pptx)
* [Week 6](/Presentaties/2018.09.28%20CBS%20Presentatie.pptx)
* [Week 7](/Presentaties/2018.10.05%20CBS%20Presentatie.pptx)
* [Week 8](/Presentaties/2018.10.12%20CBS%20Presentatie.pptx)
* [Week 9](/Presentaties/2018.10.19%20CBS%20Presentatie.pptx)
* [Week 10](/Presentaties/2018.11.02%20CBS%20Presentatie.pptx)
* [Week 11](/Presentaties/2018.11.09%20CBS%20Presentatie.pptx)
* [Week 12](/Presentaties/2018.11.16%20CBS%20Presentatie.pptx)
* [Week 13](/Presentaties/2018.11.30%20CBS%20Presentatie.pptx)
* [Week 14](/Presentaties/2018.12.07%20CBS%20Presentatie.pptx)
* [Week 15](/Presentaties/2018.12.17%20CBS%20Presentatie%20%5BAutosaved%5D.pptx)
* [Week 16](/Presentaties/2018.12.21%20CBS%20Presentatie.pptx)


<h2>Paper</h2>
De paper is een gezamenlijke bijdrage van de gehele groep. 
Omdat ik geen fervente coder ben, heb ik samen met mijn collega Seyma Irilmazbilek gericht tot de taak onderzoeken en delen van kennis(o.a. aanpak, ideeen etc.) aan ons groepsgenoten binnen dit blok. 
Zodoende was de paper meer mijn domein. 

Zo heb ik het volgende uitgevoerd binnen de paper:


* Related Work
* Gedeelte Methode
* Gedeelte Aanpak
* Bronnen uitzoeken relevant voor ons opdracht, uitdragen en citeren in het verslag (Graag verwijs ik naar kopje literatuur)
* (Code)Error Analyse samen met Timo Frionnet 
* Conclusie & Discussie
* APA Verslag, Figuren, Vergelijkingen, Bronnen
* Layout

Het gehele rapport zal ook apart worden ingeleverd. I.v.m. de vertrouwelijkheid van data zal ik niet naar het rapport verwijzen in dit portfolio.


<h2>Scrum</h2>
Omdat ik niet de grootste fan van scrum ben, heb ik dit ook nauwelijks gebruikt. Voor een breakdown van Scrum per persoon, refereer ik naar de [Scrumwise](https://www.scrumwise.com/scrum/#/people/project/kb74-2018-cbs) pagina van de CBS projectgroep.

Taken en activiteiten beknopt:  

* Domein Studie: Dit houdt in dat ik onderzoek deed naar alle gerelateerde onderzoeken op dit gebied. Maar ook naar bepaalde gehanteerde methodieken etc. Dit heb ik vervolgens geinventariseerd en uitgedragen binnen het project groep.
* Het onderzoeksplan voor ons opdracht opstellen en presenteren aan het CBS
* Linear Classifier Methode Onderzoeken & Beschrijven
* Logistic Regression Methode Onderzoeken & Beschrijven
* Word Level TF - IDF Methode Onderzoeken & Beschrijven
* Linear Regression & TF - IDF & Naive Bayes Voordelen, Nadelen omschrijven per type model
* Language Models Onderzoeken
* Formule uitleggen Extreme Gradient Boosting & Linear Regression
* Onderzoek Deep Learning Models
* Related Work - Bronnen onderzoeken gerelateerd aan ons project
* Research Paper
* POS Tagging > Text Classificatie methoden en modellen onderzoek
* Multinomial Naive Bayes > Onderzoek
* Text Classificatie methoden en modellen onderzoeken & uitschrijven
* Datasets labelen in 4 classificaties
* Confusion Matrixes maken van gelabelde datasets
* Error Analyse over Training - Test - Cross set
